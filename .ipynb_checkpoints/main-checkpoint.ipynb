{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gijineko-chan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use models that we have trained to control the JetBot for object tracking purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Jetson.GPIO as GPIO\n",
    "from jetbot import Robot\n",
    "from board import SCL, SDA\n",
    "import busio\n",
    "import smbus\n",
    "from adafruit_pca9685 import PCA9685\n",
    "import time\n",
    "from adafruit_motor import servo\n",
    "from adafruit_pca9685 import PCA9685\n",
    "import torch\n",
    "import wave\n",
    "import pyaudio\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Adafruit_PCA9685\n",
    "import time\n",
    "\n",
    "# Initialise the PCA9685 using desired address and/or bus:\n",
    "pwm = Adafruit_PCA9685.PCA9685(address = 0x40, busnum = 0)\n",
    "\n",
    "# Configure min and max servo pulse lengths\n",
    "#pulse計算、パルス幅/20000＊4096\n",
    "servo_min    = 110 # min. pulse length,最小パルス幅(0～4096)\n",
    "servo_max    = 480 # max. pulse length,最大パルス幅(0～4096)\n",
    "\n",
    "# Set frequency to 50[Hz]\n",
    "pwm.set_pwm_freq(50)\n",
    "\n",
    "def convert_deg(deg):\n",
    "    temp = (servo_max-servo_min)/2 + servo_min\n",
    "    temp += ((servo_max - servo_min)/180)*deg\n",
    "    servo_deg = int(temp)\n",
    "    return servo_deg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the TRT optimized models by executing the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_churu = TRTModule()\n",
    "model_neko = TRTModule()\n",
    "model_uni = TRTModule()\n",
    "\n",
    "model_neko.load_state_dict(torch.load('best_steering_model_xy_trt.pth'))\n",
    "model_churu.load_state_dict(torch.load('best_steering_model_xy_trt_2.pth'))\n",
    "model_uni.load_state_dict(torch.load('best_steering_model_xy_trt_3.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Pre-Processing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now loaded our model, but there's a slight issue. The format that we trained our model doesn't exactly match the format of the camera. To do that, we need to do some preprocessing. This involves the following steps:\n",
    "\n",
    "1. Convert from HWC layout to CHW layout\n",
    "2. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "3. Transfer the data from CPU memory to GPU memory\n",
    "4. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We've now defined our pre-processing function which can convert images from the camera format to the neural network input format.\n",
    "\n",
    "Now, let's start and display our camera. You should be pretty familiar with this by now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d1e27801094f749dbbfc0238fb9511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also create our robot instance which we'll need to drive the motors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define sliders to control JetBot\n",
    "> Note: We have initialize the slider values for best known configurations, however these might not work for your dataset, therefore please increase or decrease the sliders according to your setup and environment\n",
    "\n",
    "1. Speed Control (speed_gain_slider): To start your JetBot increase ``speed_gain_slider`` \n",
    "2. Steering Gain Control (steering_gain_slider): If you see JetBot is wobbling, you need to reduce ``steering_gain_slider`` till it is smooth\n",
    "3. Steering Bias control (steering_bias_slider): If you see JetBot is biased towards extreme right or extreme left side of the track, you should control this slider till JetBot start following line or track in the center.  This accounts for motor biases as well as camera offsets\n",
    "\n",
    "> Note: You should play around above mentioned sliders with lower speed to get smooth JetBot object following behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf60a5a466548d9b6972dbb95d68726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537fd0c89a3e450184c6c923a646de95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e60cc1c8e5141c1a04fa2d4e17427c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0dad69addf43558f4787b5eeccce61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's display some sliders that will let us see what JetBot is thinking.  The x and y sliders will display the predicted x, y values.\n",
    "\n",
    "The steering slider will display our estimated steering value.  Please remember, this value isn't the actual angle of the target, but simply a value that is\n",
    "nearly proportional.  When the actual angle is ``0``, this will be zero, and it will increase / decrease with the actual angle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259224e4f6474e08b01bf73c157d486c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical'), FloatSlider(value=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c18cab2d07040dd97b5b1182449f818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec900f3815a74aa589a35ceb2b1ff6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "display(x_slider, steering_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create play-wav function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_wav(filename):\n",
    "    wf = wave.open(filename, mode='rb')\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(\n",
    "        format=p.get_format_from_width(wf.getsampwidth()),\n",
    "        channels=wf.getnchannels(),\n",
    "        rate=wf.getframerate(),\n",
    "        output=True\n",
    "        # output_device_index=1\n",
    "        ) \n",
    "    chunk = 1024 \n",
    "    wf.rewind() \n",
    "    buf = wf.readframes(chunk)\n",
    "    while buf:\n",
    "        stream.write(buf)\n",
    "        buf = wf.readframes(chunk)\n",
    "            \n",
    "    stream.close()\n",
    "    p.terminate()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a function that will get called whenever the camera's value changes. This function will do the following steps\n",
    "\n",
    "1. Pre-process the camera image\n",
    "2. Make a sound and move the servo motor\n",
    "3. Execute the neural network\n",
    "4. Compute the approximate steering value\n",
    "5. Control the motors using proportional / derivative control (PD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "count = 0\n",
    "tale_now_angle = [0,0]\n",
    "tale_now_phase = 0\n",
    "tale_lists = None\n",
    "\n",
    "xy = None\n",
    "image = None\n",
    "\n",
    "wav_filename = \"\"\n",
    "wav_interval = 0\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, count, xy, image, tale_now_angle, tale_now_phase, tale_interval_time, tale_lists,wav_filename,wav_interval\n",
    "    count+=1\n",
    "    image = change['new']\n",
    "    if xy is None:\n",
    "        xy = model_neko(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "        wav_filename = \"wav/cat_angry.wav\"\n",
    "        wav_interval = 7\n",
    "    \n",
    "    # モデル切り替え判定 (change model)\n",
    "    if count >= 20*10:\n",
    "        random = np.random.randint(0,100)\n",
    "        if random <= 33:\n",
    "            xy = model_neko(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "            tale_lists = [[30,80],[0,81],[-30,80],[0,81]]\n",
    "            wav_filename = \"wav/cat_angry.wav\"\n",
    "            wav_interval = 7\n",
    "            print(\"neko\")\n",
    "        elif random <= 66:\n",
    "            xy = model_churu(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "            tale_lists = [[0,70],[20,80],[0,90],[-20,70]]\n",
    "            wav_filename = \"wav/cat_calling.wav\"\n",
    "            wav_interval = 5\n",
    "            print(\"churu\")\n",
    "        else:\n",
    "            xy = model_uni(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "            tale_lists = [[0,85]]\n",
    "            wav_filename = \"\"\n",
    "            wav_interval = 0\n",
    "            print(\"uni\")\n",
    "        count = 0\n",
    "        if len(tale_lists) < tale_now_phase+1:\n",
    "            tale_now_phase = 0\n",
    "        \n",
    "    # 尻尾動かす (Moving tale\n",
    "    if tale_lists != None:\n",
    "        ### 計算\n",
    "        # x （横）\n",
    "        if tale_lists[tale_now_phase][0] > tale_now_angle[0]:\n",
    "            tale_now_angle[0] += 2\n",
    "        if tale_lists[tale_now_phase][0] < tale_now_angle[0]:\n",
    "            tale_now_angle[0] -= 2\n",
    "        # y （縦）\n",
    "        if tale_lists[tale_now_phase][1] > tale_now_angle[1]:\n",
    "            tale_now_angle[1] += 2\n",
    "        if tale_lists[tale_now_phase][1] < tale_now_angle[1]:\n",
    "            tale_now_angle[1] -= 2\n",
    "        \n",
    "        # 移動\n",
    "        pwm.set_pwm(0, 0, convert_deg(tale_now_angle[0]))\n",
    "        pwm.set_pwm(2, 0, convert_deg(tale_now_angle[1]))\n",
    "        \n",
    "        # Phase 移行確認\n",
    "        if tale_now_angle[0] == tale_lists[tale_now_phase][0]:\n",
    "            if tale_now_angle[1] == tale_lists[tale_now_phase][1]:\n",
    "                if len(tale_lists) <= tale_now_phase+1:\n",
    "                    tale_now_phase = 0\n",
    "                else:\n",
    "                    tale_now_phase += 1\n",
    "\n",
    "   #鳴き声 (sound)\n",
    "    if wav_filename != \"\":\n",
    "        if wav_interval != 0:\n",
    "            if count%(20*wav_interval) == 0:\n",
    "                play_wav(wav_filename)\n",
    "                \n",
    "        \n",
    "    #image = change['new']\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "    \n",
    "    speed_slider.value = speed_gain_slider.value\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias_slider.value\n",
    "    \n",
    "    robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "    \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We've created our neural network execution function, but now we need to attach it to the camera for processing.\n",
    "\n",
    "We accomplish that with the observe function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">WARNING: This code will move the robot!! Please make sure your robot has clearance and it is on Lego or Track you have collected data on. The road follower should work, but the neural network is only as good as the data it's trained on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churu\n",
      "uni\n",
      "uni\n",
      "uni\n",
      "churu\n",
      "neko\n",
      "uni\n",
      "churu\n",
      "neko\n",
      "uni\n",
      "neko\n"
     ]
    }
   ],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! If your robot is plugged in it should now be generating new commands with each new camera frame. \n",
    "\n",
    "You can now place JetBot on  Lego or Track you have collected data on and see whether it can follow track.\n",
    "\n",
    "If you want to stop this behavior, you can unattach this callback by executing the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's close the camera conneciton properly so that we can use the camera in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all about our work!\n",
    "What kind of cat has your gijinekochan become?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
